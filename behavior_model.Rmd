---
title: "Desarrollo de Modelo Behavior para TDC"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 3
    number_sections: true
    code_folding: hide
    keep_md: yes
---

**Sinopsis**

El Modelo de behavior de tarjetas de crédito tiene como objetivo estimar la probabilidad de incumplimiento de los tarjetahabientes en un período de tiempo, según su propensión de poder registrar una mora de noventa días o más en los próximos seis meses, lo cual permite optimizar la gestión de cobro, a su vez este modelo suele ser una herramienta útil en los aumentos de límite de tarjetas de crédito debido a que nos ayuda a mitigar el riesgo de perdida por incumplimiento.

**Flujo de trabajo para el desarrollo del modelo**

Para la realización del modelo se tomarán en cuenta los siguiente pasos:

1. Delimitación de los períodos de observación y desempeño, siendo estos, período de observación: de mayo 2020 a octubre 2020 y período de desempeño: de noviembre 2020 a abril 2021

2. Se excluyen los clientes que a la fecha octubre 2020 (fecha divisoria) se encontraban incumplidos.

3. Etiquetas de buenos/malos clientes basado en la altura máxima de mora alcanzada que se considera como incumplimiento (noventa días) en el período de desempeño (noviembre 2020 a abril 2021).

4. Partición de los datos en un subconjunto de entrenamiento (70%) y un subconjunto de prueba (30%).

5. Con los datos de entrenamiento se construyen posibles variables predictoras en el período de observación (mayo 2020 a octubre 2020).

6. Se evalúa la potencia discriminatoria de cada variable predictora construida en el paso anterior mediante el cálculo del coeficiente gini, luego se seleccionan las variables predictivas y se ajusta el modelo de regresión logística.

7. Con los datos de prueba (30%), y el modelo final, se calculan las probabilidades de incumplimiento y se determina un gini de prueba.

**Fuente de datos**

Los datos utilizados para la elaboración del modelo pertenecen a la cartera de TDC y datos de interes suministrados por el area de inteligencia competitiva, para más información, en el siguiente enlace encontrará cómo se construyen y definen algunas de las variables y bases utilizadas [Data Documentation](https://github.com/josecoello21/Behavior_Model/blob/main/CodeBook.md)<base target="_top"/>.

**Librerias**

```{r echo=TRUE, eval=FALSE}
library(purrr)
library(lubridate)
library(data.table)
library(scorecard)
library(ROSE)
```

```{r echo=FALSE, message=FALSE}
source('libraries_and_functions.R')
```

# Carga y preparación de los datos

```{r}
# carga de base tdc
base_tdc <- readRDS(file = 'data_sets_rds/tdc_abr21.RDS') |> 
    as.data.table()

dim(base_tdc)
```

La cartera de tarjeta de créditos cuenta con un total de `r format(nrow(base_tdc), nsmall = 0, big.mark = ',')` registros y `r ncol(base_tdc)` columnas.

Una vez cargados los datos realizamos los siguientes pasos:

1. Selección de variables de interes: `cedula`, `nro_tarjeta`, `bine`, `sexo`, `edo_civil`, `tipo_res`, `fecha_nac`, `fecha_emi`, `nro_dep`, `vc_2020`, `vc_2021`.

```{r eval=FALSE}
# variables de interes
base_tdc[
    , cedula := paste0(.SD, collapse = ''),
    by = seq_along(T5CDTI),
    .SDcols = c('T5CDTI', 'T5UNNB')
    ][
        , .('cedula' = cedula, 'nro_tarjeta' = T5NRTA, 'bine' = T5BINE,
            'sexo' = T5CDSE, 'edo_civil' = T5DSEC, 'tipo_res' = T5DSTR,
            'fecha_nac' = T5PWNB, 'fecha_emi' = T5MQNB, 'nro_dep' = T5T3NB, 
            'vc_2020' = H3HSNB, 'vc_2021' = H3HTNB)
        ] -> base_tdc
```

2. Selección de registros con información del comportamiento de pago entre las fechas enero 2020 a abril 2021.

```{r eval=FALSE}
# vectores de comportamiento de 12 caracteres 2020 y 4 caracteres 2021
base_tdc[
    , `:=` (vc_2020 = gsub(pattern = '\\s',
                           replacement = '',
                           x = vc_2020
                           ),
            vc_2021 = gsub(pattern = '\\s',
                           replacement = '',
                           x = vc_2021
                           )
            )
    ][
        nchar(vc_2020) == 12 & nchar(vc_2021) == 4
        ] -> base_tdc

# reformateo de datos
base_tdc[
    , `:=` (sexo = factor(sexo),
            edo_civil = factor(edo_civil),
            tipo_res = factor(tipo_res),
            fecha_nac = ymd(fecha_nac),
            fecha_emi = ymd(fecha_emi)
            )
    ]
```

3. Exclusión de registros en estado de incumplimiento (90 días o más) al cierre del período de observación  octubre 2020. 

```{r eval=FALSE}
# Exclusión de clientes oct20 (fecha divisoria) que se encuentran incumplidos
incumplido <- '[3456789GHIJKLM]'

base_tdc[
    , mora_oct_2020 := substr(x = vc_2020, start = 10, stop = 10)
    ][
        !grepl(pattern = incumplido, x = mora_oct_2020)
        ] -> base_tdc
```

4. Se detecta la altura de mora alcanzada durante el período de desempeño (noviembre 2020 a abril 2021) y creamos la variable `Status` que nos indica si el cliente alcanzó un estado de mora menor a 90 días, si este es el caso se etiqueta como bueno = 0 ó si el cliente obtuvo una mora de 90 días o más, estos casos serán considerados como incumplido = 1.

```{r eval=FALSE}
# Etiqueta buenos/malos en el período de comportamiento nov20-abr21
base_tdc[
    , `:=` (mora_nov20_dic20 = {tmp <- substr(x = vc_2020, 
                                              start = 11, 
                                              stop = 12); tmp},
            mora_nov20_abr21 = {tmp2 <- paste0(tmp, vc_2021); tmp2},
            status = {tmp3 <- grepl(pattern = incumplido, x = tmp2); 
                      factor(as.integer(tmp3))
                      }
            )
    ]
```

5. Obtenemos la edad y antiguedad de la tarjeta de crédito para cada uno de los registros al inicio del período de observación.

```{r eval=FALSE}
# Edad y antiguedad de la tarjeta
fecha_obs <- ymd('2020-04-30')

base_tdc[
    , `:=` (edad = {tmp_age <- interval(start = fecha_nac, end = fecha_obs);
                    tmp_age2 <- as.period(tmp_age); 
                    lubridate::year(tmp_age2)
                    },
            antiguedad_tdc = {tmp_age_tdc <- interval(start = fecha_emi, end = fecha_obs);
                              tmp_age_tdc2 <- as.period(tmp_age_tdc); 
                              lubridate::year(tmp_age_tdc2)
                              }
            )
    ]

```

6. Partición de los datos en un subconjunto de entrenamiento (70%) y un subconjunto de prueba (30%).

```{r eval=FALSE}
# Partición de datos entrenamiento 70% y prueba 30%
size <- prod(nrow(base_tdc), .7) |> trunc()

# datos de entrenamiento
set.seed(123)
# subconjunto datos de entrenamiento
train_index <- sample(x = 1:nrow(base_tdc), size = size)

# subconjunto datos de prueba
test_index <- c(1:nrow(base_tdc))[
    !(1:nrow(base_tdc) %in% train_index)
    ]

# dt train
base_tdc[ 
    train_index 
    ] -> dt_train

# dt test
base_tdc[
    test_index
    ] -> dt_test
```

# Construcción de variables

Una vez obtenidos los registros de interes y algunas variables necesarias para el desarrollo del modelo, procedemos a construir posibles variables predictoras en el período de observación.

1. Obtenemos el número de moras que los tarjetahabientes obtuvieron durante el período de observación.

```{r eval=FALSE}
# variables a excluir
vrs <- c('bine','fecha_nac','fecha_emi','mora_oct_2020',
         'mora_nov20_dic20','mora_nov20_abr21')

# número de veces en mora durante el período de observación
lapply(X = dt_sets, 
       function(x){
           x[
               ,!..vrs
               ][
                   , `:=` (mora_may20_oct20 = {tmp <- substr(x = vc_2020,
                                                             start = 5,
                                                             stop = 10)},
                           nro_moras_obs = {tmp2 <- strsplit(x = tmp, split = '')
                           tmp3 <- unlist(tmp2)
                           tmp4 <- grepl(pattern = '[^NS]', x = tmp3)
                           tmp5 <- sum(tmp4)}
                           ),
                   by = nro_tarjeta
                   ]
           }) -> dt_sets
```

2. Calculo del saldo promedio dolarizado en cuenta financiera durante el período de observación (mayo 2020 a octubre 2020).

```{r eval=FALSE}
# conversion de saldos bs a dolar y promedio de saldos dolarizados may20-oct20
col_saldo <- names(dt_sets$dt_train)[
    grepl(pattern = 'saldo', x = names(dt_sets$dt_train))
    ]

lapply(
    X = dt_sets, 
    FUN = avg_dolar,
    dt_dolar = precio_dolar,
    cols_saldos = col_saldo,
    name_var = 'avg_saldo'
    ) -> dt_sets
```

3. Calculo de depósito promedio dolarizado en cuenta financiera durante el período de observación (mayo 2020 a octubre 2020).

```{r eval=FALSE}
# depositos en cuenta dolarizado may20-oct20
col_dep <- names(dt_sets$dt_train)[
    grepl(pattern = '_dep_', x = names(dt_sets$dt_train))
    ]

lapply(
    X = dt_sets, 
    FUN = avg_dolar,
    dt_dolar = precio_dolar,
    cols_saldos = col_dep,
    name_var = 'avg_dep'
    ) -> dt_sets
```

# Construcción de bins sobre variables predictoras

En esta etapa se generaron los distintos intervalos sobre las variables predictoras, tomando en consideración la lógica que se esperaría observar en cada una de ellas.

Para ello se utilizarón las métricas coeficiente de Gini, peso de la evidencia conocido también como (WOE) por sus siglas en inglés y el valor de la información (IV), estas proporcionan un marco para el análisis exploratorio y recategorización de variables de clasificadores binarios, han sido utilizado ampliamente en el mundo del riesgo de crédito durante varias décadas.

- **Peso de la evidencia (WOE)**: muestra el poder predictivo de una variable independiente en relación con la variable dependiente. Evolucionó con  el puntaje de crédito para magnificar el poder de separación entre un buen cliente y un mal cliente, se define como:

\begin{equation}
WOE\ =\ ln( \frac{Distribucion\ de\ malos}{Distribucion\ de\ buenos} )
\end{equation}

Valores WOE positivos significa que la distribución de malos es mayor a la distribución de buenos.

- **Valor de la información (IV)**: ayuda a seleccionar las variables utilizando su orden de importancia y el valor de la información después de la agrupación.

\begin{equation}
IV\ =\ \sum (\%\ de\ buenos\ - \%\ de\ malos) * WOE
\end{equation}

```{r echo=FALSE}
# carga de datos
dt_path <- c('result/dt_train3.RDS', 'result/dt_test3.RDS')
dt_sets <- lapply(X = dt_path, FUN = readRDS)
names(dt_sets) <- c('dt_train', 'dt_test')
total_iv <- readRDS('result/total_iv.RDS')
# iv summary
vars <- names(dt_sets$dt_train)[ 
    grep(pattern = '2$', x = names(dt_sets$dt_train)) 
    ]
```

```{r}
# resumen coeficiente de gini por variable
lapply(
    X = vars, 
    FUN = gini,
    dt = dt_sets$dt_train, 
    y = 'status'
    ) -> gini_summ

names(gini_summ) <- vars

lapply(X = gini_summ, FUN = kable, digits = 3)

# total peso de evidencia y valor de informacion por variable
kable(x = total_iv, digits = 3)
```

# Modelo de regresión logística

En los problemas de clasificación, una desigualdad en las frecuencias de las clases observadas puede tener un impacto negativo en el ajuste del modelo. Una técnica para resolver este desequilibrio de clases es crear una muestra de datos sintéticos ampliando el espacio de características de la clase minoritaria, de esta manera poder mitigar este problema [Subsampling Techniques](https://topepo.github.io/caret/subsampling-for-class-imbalances.html)<base target="_top"/>.

```{r}
# frecuencia de las clases de la variable respuesta status
lapply(
    X = dt_sets, 
    function(x){
        kable(table(x$status))
        }
    )

# prop. de las clases de la variable respuesta status
lapply(
    X = dt_sets, 
    function(x){
        kable(prop.table(table(x$status)))
        }
    )
```

Para no modificar en gran medida la naturaleza del problema en lo que refiere al desbalanceo de clases, se decidió configurar el conjunto de datos de entrenamiento en una relación de 80% de registros con características de clientes al día y un 20% de registros de características de clientes incumplidos.

```{r}
# balanceo de clases del conjunto de entrenamiento
# (prop. de buenos y malos igual a 80%-20%)
ROSE(
    status ~ ., 
    data = dt_sets$dt_train, 
    N = nrow(dt_sets$dt_train), 
    p = .2, seed = 123
    )$data |> 
    as.data.table() -> dt_balanced

# prop. de las clases de la variable status en los datos balanceados
prop.table(table(dt_balanced$status)) |> 
    round(digits = 3)
```

```{r echo=FALSE}
# carga de base
path_dt <- c('result/dt_train_woe.RDS',
             'result/dt_test_woe.RDS',
             'result/dt_balanced_woe.RDS')
lapply(
    X = path_dt, 
    FUN = readRDS
    ) -> dt_woe

names(dt_woe) <- c('dt_train', 'dt_test', 'dt_balanced')
```

La regresión logística mide la relación entre una o más variables independientes y la variable dependiente categórica mediante la estimación de probabilidades a través de una función logística, que es la distribución logística acumulativa, su fórmula viene dada por:

\begin{equation}
\ln\left(\frac{P\left(X\right)}{1-P\left(X\right)}\right) = intercept + \beta_{1}x +...+ \beta_{n}x
\end{equation}

```{r}
# construccion del modelo logistico
set.seed(123)
glm(
    status ~ .,
    family = binomial(link = 'logit'),
    data = dt_woe$dt_balanced
    ) -> logit_model

summ(logit_model, model.info = FALSE)
```

Evaluamos el rendimiento del modelo, para ello observamos las métricas de rendimiento tales como:

- Gini general del modelo.
- Matriz de confusión.
- Precisión, recall o sensibilidad y media armónica.
- AUC, KS.

**Gini general del modelo**

```{r echo=FALSE}
# predicciones
lapply(
    X = dt_woe, 
    FUN = predict, 
    object =logit_model, 
    type = 'response'
    ) -> predict_model

mapply(
    function(x,y){
        x[
            , prob := y  
        ]},
    dt_woe, predict_model, SIMPLIFY = F
    ) -> dt_woe
```

```{r}
# gini model
lapply(
    X = predict_model, 
    FUN = quantile, 
    probs = seq(0,1,.1)
    ) -> breaks

mapply(
    FUN = gini, 
    dt = dt_woe, 
    x = 'prob', 
    y = 'status', 
    breaks = breaks, 
    SIMPLIFY = F
    ) -> gini_model

kable(x = gini_model$dt_test, digits = 3)
```

**Matriz de confusión**

```{r}
# otras metricas
threshold = 0.181
mapply(
    function(x,y){
        perf_eva(
            pred = x,
            label = as.numeric(as.character(y$status)), 
            confusion_matrix = TRUE,
            threshold = threshold,
            show_plot = FALSE
            )
        }, 
    predict_model, dt_woe, SIMPLIFY = F
    ) -> metrics

# matriz de confusión
metrics$dt_test$confusion_matrix
```

**Precisión, recall o sensibilidad y media armónica**

```{r}
# precisión, recall, media armónica entre presición y recall
accuracy.meas(
    response = dt_woe$dt_test$status,
    predicted =  predict_model$dt_test,
    threshold = threshold
    )
```

**AUC, KS**

```{r}
# otras métricas
metrics$dt_test$binomial_metric
```


Este documento contiene un resumen general y resultados más relevantes del desarrollo del modelo behavior para TDC, para mayor información sobre flujo de trabajo y código general del proyecto [Github](https://github.com/josecoello21/Behavior_Model.git)<base target="_top"/>.  

<div class = "tocify-extend-page" data-unique = "tocify-extend-page" style = "height: 0;"> </div>